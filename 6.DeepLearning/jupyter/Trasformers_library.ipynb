{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "077d4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers xformers datasets -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d39783b",
   "metadata": {},
   "source": [
    "## pipeline - 감정 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8246c5d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998819828033447}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998819828033447}, {'label': 'NEGATIVE', 'score': 0.5308623313903809}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "results = classifier(\"We are very happy.\")\n",
    "print(results)\n",
    "\n",
    "results = classifier([\"We are very happy.\", \"We hope you don't hate it.\"])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec11e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9585047960281372},\n",
       " {'label': 'LABEL_0', 'score': 0.9480631947517395},\n",
       " {'label': 'LABEL_0', 'score': 0.9478973150253296},\n",
       " {'label': 'LABEL_1', 'score': 0.9728173613548279},\n",
       " {'label': 'LABEL_0', 'score': 0.6631661653518677}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"matthewburke/korean_sentiment\")\n",
    "classifier([\"괜찮은데?\", \"생각보단 별로네\", \"그저그래\", \"영화 재미있었다\", \"평범했어\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bfc139",
   "metadata": {},
   "source": [
    "## pipeline - 텍스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d66e53aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf952544bb946078f03852dd0f73023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b5fcccaecd43efb08664e0bc47cee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2625bbaa8df4d0fbe9d3a0045455110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5cb6265021d4ab5955152b1830d9a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0264a35eeef4110bdfc32a6fc16e0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29646fd752884929aeaf442f3fd49140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a dream in my head: if we're still alive after 9/11 I would see this building for what it was: a world where we live under the most terrifying threat possible; we wouldn't have had it any other way.\n",
      "\n",
      "But it never takes very long for people to get the idea that if they were killed in the US, somehow, they would now know precisely how many people this building is connected to. It's a simple fact, but it's one of the most insidious: what you're about to see on the ground in the sky really really reflects how fragile we're in this moment, and how we're still under attack: how the terrorists keep moving, as if they'd find a home, and then decide to fight our way to one or another corner of the world. So, for example, look at the WTC. Those buildings look like what we would see at a major airport: this sort of floating, glowing, giant structure or whatever.\n",
      "\n",
      "I just wanted to check in with you some more.\n",
      "\n",
      "Yeah, I had a little chat with a guy there, who's writing from London about the attacks. He's like a man about this, and now he's kind of got the story from one terrorist attack. And he said: I actually went to the building and I watched the aftermath for a while and it was the first time I went through it.\n",
      "\n",
      "I said to him: it was scary, but it didn't feel like I was fighting the government. The people didn't seem scared.\n",
      "\n",
      "They were just there watching.\n",
      "\n",
      "Okay.\n",
      "\n",
      "They were watching me after they made it. And they had the picture where they were standing, in the ground. And the picture is clearly from the second tower, right after what they did to me. And their first action?\n",
      "\n",
      "It looked like you're standing on the second one, and I went: what the hell!?\n",
      "\n",
      "The person that saw this picture has a heart attack in his left calf, my arm is about to go off, and I was just going over there and I started running, and it was over there, and I didn't stop. And then he took off on his way down, and I think that's what I thought was the first action of this explosion. And what they had done there, they were doing there, not me, but people in the building at the other end of the main street. And it made me really scared, because the second building was standing off to the side: where they had been taking off for some time. And now they were flying a couple of times, like one by one.\n",
      "\n",
      "So I don't know if it was going to blow up, but we saw this and we thought this is another one of these kind of explosions that we can experience after a few minutes. We thought – it's not really like we've never heard of the first one, but it was interesting that people get that feeling that there were actually more people up in that building, right? That's what it was, because they wouldn't know what they were going to catch when they were flying. And for the first time we remember a lot of that.\n",
      "\n",
      "And the building didn't go down. Instead, we saw it coming back, that something bigger had gone through them.\n",
      "\n",
      "Yeah, it did, man.\n",
      "\n",
      "What's that like to look around you?\n",
      "\n",
      "Me, I didn't see that building. Nothing at first. It took me so long to even remember. And it was terrifying.\n",
      "\n",
      "We didn't know what was going on. So we moved outside again, and they set fire to the building. They started fires to get water that had been in the building, from the building to the building, and that's where we saw the building go down.\n",
      "\n",
      "What did you do? Do you now see what was going on? What do you keep up with on the ground?\n",
      "\n",
      "So we've been talking, not just about just the buildings, but really about the people that were there, they're still, they're in the building. And the biggest thing was the way they were holding their bodies. We heard them cry out in this big picture-like video that all people were on the ground and screaming. And I think that's the first time we've seen anything like this at our house. I think that's the first.\n",
      "\n",
      "What do you remember, though?\n",
      "\n",
      "I remember sitting, feeling slightly ill. I remember my friends were crying just at the hospital from being treated, and I remember they were very worried about my friends. I remember that as well, but everything is weird enthusiasm that they had for us, and I felt like I had to be the center of attention. As you can see, we're really talking just about the things they talked about. We\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "\n",
    "result = generator(\"I have a dream\", max_length=1000)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87a0aa43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ea94322d1947179af44e04199cba09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1058f7743624466189985ad0af04c7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9c294bbf504bf8bcaa72b73545187e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아름다운 밤이에요.\" 하는 말이었다.\n",
      "이순신과 이순신은 서로 얼굴을 마주 바라보며 서 있고 있었다.\n",
      "그리고 그 모습이 매우 대조적이었다.\n",
      "그 두 사람의 가슴도 아주 대조적이었다.\n",
      "그것은 그가 '삼촌', 즉 '삼촌'과 전혀 다르다.\n",
      "이순신은 '그놈'에게서 어떤 감흥이 있었던 것일까?\n",
      "이순신은 이렇게 기억했다.\n",
      "\"이순신을 죽이려고 했어요.\"\n",
      "이순신은, 그렇게 말하고, 그런 말을 하는 것이다.\n",
      "만약에 그가 그렇게 했을까?\n",
      "그저 이 광경을 보면 참 안심이 안 되었으니.\n",
      "이순신은 그 동안 두 눈을 번쩍 뜨고 있었으니까.\n",
      "순신 역시 눈만 뜨고 있었으니까.\n",
      "오히려 마음이 상했던 것이다.\n",
      "그러므로 이번 전투에서는 결코 그럴 필요도 없었기 때문이다.\n",
      "그리고 그런 생각을 할 때면 순서는 이미 삼촌이었다.\n",
      "이순신은 삼촌이었다.\n",
      "그는萌과 그의 친구들의 이야기를 들으며 자신의 마음을 정리했다.\n",
      "그리고 그 대화를 들은 적이 있었다.\n",
      "\"저기 보시오.\"\n",
      "순서는, 자신이 삼촌의 아들이란 생각을 하며 서 있는 그 자리에 그대로 서 있었다.\n",
      "순서는 마치 꿈속에서나 보이는 이런 사람 같아 보였다.\n",
      "어디선가 날아오는 총소리가 나는 듯하고.\n",
      "순서는 순서와 껄껄껄 웃으며 이야기를 이어가고 있었다.\n",
      "이순신은 그렇게, 순서가 그렇게 생각하며 고개를 끄덕였다.\n",
      "순서는, 그 생각에 순간 가슴이 설레기 시작했다.\n",
      "그렇게 생각하면 이미 순서는 순서를 잘 알고 있었다.\n",
      "그러나 순서는 순서와 자신의 감정을 동시에 이해할 수 있었다.\n",
      "그런 순서는 순서의 그런 마음을 충분히 이해한 모양이었다.\n",
      "순서는, 순서가 자신이 순서와 자신의 감정을 함께 이해하고 있다는 사실을 알게 되었다.\n",
      "순서와 저는 지금 이 순서의 심정이 어떤 것인지 잘 알고 있는 것이다.\n",
      "순서는 두 손을 마주 잡고 있는 자신의 머리카락을 만지작거리며 말했다.\n",
      "순서는, 순서의 머릿속에 떠오르는 감정을, 순서는 그 감정을 함께 이해할 수 있었다.\n",
      "순서는 머릿 상동인을 보면서 가슴이 설레었다.\n",
      "그러나 순서는, 순서가 머릿동인의 말에 동의하지 않았다.\n",
      "순서가 순서와 자신의 관계를 이해할 수 있도록 순서를 만져주는 것만 같았다.\n",
      "순서는 순서가 머릿동인의 행동에 대해 말하자, 갑자기, 자신이 순서를 생각하는 눈초리를 보냈다.\n",
      "순서는, 순서가 순서가 마음속에 있는 것을 이해하도록 순서를 만져주었다.\n",
      "그는, 순서가 순서를 생각하며 순서를 다시 만져주려고 했던 일을 떠올렸다.\n",
      "그리고 순서가 이런 느낌을 품도록, 순서가 순서를 위해 이 일을 했어야 하는지도 생각하고 있었다.\n",
      "순서는 순서가 순서가 순서를 생각하는 마음이 얼마나 큰지 느낄 수 있게 했다.\n",
      "순서는 순서가 순서를 진심으로 사랑해주는 마음이 얼마나 큰지 알고, 순서도 순서가 순서가 순서를 좋아한다는 사실조차 잘 알고 있었다.\n",
      "순서는 순서가 자신에게 무슨 일이 있었는지 잘 알고 있었다.\n",
      "그는 순서가 순서가 순서를 사랑하도록 허락해 주었다고 생각한다.\n",
      "순서는 순서가 항상 순서를 사랑할 줄 알았던 것은 아니었다.\n",
      "순서는 순서와 자기가 그렇게 생각했었다고, 정말 고마워하며 순서가 순서와 자신을 이해하는 데 큰 도움이 되었던 것을 무척 자랑하게 생각했었다.\n",
      "\"그들은 모두 내 사랑하는 사람들입니다. 이렇게 아름다운 밤을 보낼 수 있게 해준 이들을 생각하니 저도 마음이 흐뭇해지고 행복합니다. 제 꿈은 아주 밝은 빛을 띠고 있는데요.\"\n",
      "그는 순서가 순서가 순서와 자기를 이해하는 데 도움이 된 것을 아주 자랑스러워하며 말했다.\n",
      "이순신은, 순서가 순서의 진심을 이해할 줄 아는 사람은 순서가 아니라고 생각한다.\n",
      "순서는 순서가 순서가 그런 사람의 사랑을 얼마나 더 알고 있는지 알고 있었다.\n",
      "순서는, 순서가 순서 자신을 사랑하는 사람이라면 순서가 순서가 순서가 순서가 아니라고 말할 수 있는지 잘 안다.\n",
      "순서가 순서와 자신을 인정해 주는 것은 순서가 순서가 자신의 감정에 대해 잘 알고 있다는 생각 때문이다.\n",
      "순서는 순서가 순서를 사랑하도록 허락했다.\n",
      "순서는 그렇게 순서가 자신을 사랑하도록 허락한 것이다.\n",
      "순서는 순서가 순서가 순서가 순서가 되었다는 사실을 몹시 기뻐하면서 순서의 얼굴이 환하게 빛나는 것을 보면서 순서가 순서가 사랑하고 있다고 생각한다.\n",
      "\"그럼 저희들은 저희들에게 잘해 줄 수 있을지 모르겠습니다.\"\n",
      "순서는, 순서가 순서가 순서가 아니라고 말하면 순서가 오히려 더 잘해 줄 자신이 없다는 생각을 하고 있었다.\n",
      "이렇게 서로에 대한 인정심 같은 감정을 모두 품고 있었으니까.\n",
      "순서는 순서가 순서가 아니라는 것이 자랑스럽고 기뻤다.\n",
      "순서는 그런 순서의 표정을 보면서 자신이 순서가 되기 위해 애쓰고 있는 자신을 부끄럽게 생각했다.\n",
      "순서는 순서가 순실이 되었으면 하고 바라는 것을 솔직히 로빈훗하게 생각했다.\n",
      "순서는 순서가 순실이 된 것을 기뻐하고 있었기 때문이다.\n",
      "이순신은 순서가 순서가 되었다고 말할 줄 알았던 것이다.\n",
      "그 말을 듣자 순서는 순서가 순서가 되었다\n",
      "든지, 순서가 순대가 된 것이 순서가 될 수 없다는 것이 무척 자랑스럽기만 했다.\n",
      "\"저희들에게도 그렇게 말하겠습니다. 순서가 순서가 될 수 있으니까요.\"\n",
      "어쩌면 순서가 순성이 된다고 느낄지도 몰랐다.\n",
      "순서가 순서가 되었으면 순서가 사랑받을 수 있게 되기를 기원하면서, 순\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 모델 로딩\n",
    "generator = pipeline(\"text-generation\", max_length=1000,\n",
    "                     model=\"skt/kogpt2-base-v2\")\n",
    "\n",
    "# 모델 이용\n",
    "result = generator(\"아름다운 밤이에요.\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f742f0",
   "metadata": {},
   "source": [
    "## pipeline - 이미지 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a5dcdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 5dca96d (https://huggingface.co/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d033934985448e8d81a1d7b07d938f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1bffa447fca4b30a765bad5e0a8685d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d958642ce7f4830a2bff5bcfeb13bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to ydshieh/vit-gpt2-coco-en and revision 65636df (https://huggingface.co/ydshieh/vit-gpt2-coco-en).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.9905232787132263, 'label': 'macaw'}, {'score': 0.005603462923318148, 'label': 'African grey, African gray, Psittacus erithacus'}, {'score': 0.0010569036239758134, 'label': 'toucan'}, {'score': 0.000681147095747292, 'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita'}, {'score': 0.0006714338669553399, 'label': 'lorikeet'}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d228b5dd835a4b59afd3686bf124440d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/4.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc05a9548434c03b6241b641021e82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/982M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from transformers import pipeline\n",
    "\n",
    "img = \"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png\"\n",
    "\n",
    "# 이미지 분류\n",
    "classifier = pipeline(\"image-classification\")\n",
    "result = classifier(img)\n",
    "print(result)\n",
    "\n",
    "# 이미지 설명\n",
    "caption = pipeline(\"image-to-text\")\n",
    "result = caption(img)\n",
    "print(result)\n",
    "\n",
    "# 이미지 보기\n",
    "Image(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4903aee6",
   "metadata": {},
   "source": [
    "## pipeline - 음성 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e7909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 오디오 데이터셋 로딩\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f032df4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 오디오 파일 재생\n",
    "from IPython.display import Audio\n",
    "Audio(dataset[0][\"audio\"]['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cedbff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# 모델 로딩\n",
    "speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# 모델 사용\n",
    "result = speech_recognizer(dataset[0][\"audio\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32c097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 오디오 데이터셋 로딩\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"ko-KR\", split=\"train\")\n",
    "print(dataset)\n",
    "\n",
    "# 모델 로딩\n",
    "speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"Hyuk/wav2vec2-korean-v2\")\n",
    "\n",
    "# 모델 사용\n",
    "result = speech_recognizer(dataset[1][\"audio\"])\n",
    "print(result)\n",
    "\n",
    "# 오디오 파일 재생\n",
    "Audio(dataset[1][\"audio\"]['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6ee41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2274a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12694182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f4a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d456efd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5834ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d83cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758ff11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f645ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad82963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b875a8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef90da8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20863f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
