{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b89c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00886404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000, 10)\n",
      "(10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 표로 만들기\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8520a078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50890 (198.79 KB)\n",
      "Trainable params: 50890 (198.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "X = tf.keras.Input([784])\n",
    "H = tf.keras.layers.Dense(64, activation='swish')(X)\n",
    "Y = tf.keras.layers.Dense(10, activation='softmax')(H)\n",
    "model = tf.keras.Model(X,Y)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "273456f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 4.7017 - accuracy: 0.7946 - val_loss: 0.6708 - val_accuracy: 0.8630\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5810 - accuracy: 0.8869 - val_loss: 0.4708 - val_accuracy: 0.9108\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4065 - accuracy: 0.9185 - val_loss: 0.3907 - val_accuracy: 0.9288\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3220 - accuracy: 0.9337 - val_loss: 0.3651 - val_accuracy: 0.9342\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2728 - accuracy: 0.9404 - val_loss: 0.3366 - val_accuracy: 0.9354\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2333 - accuracy: 0.9472 - val_loss: 0.3156 - val_accuracy: 0.9440\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2177 - accuracy: 0.9519 - val_loss: 0.3411 - val_accuracy: 0.9428\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2018 - accuracy: 0.9549 - val_loss: 0.3558 - val_accuracy: 0.9405\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1866 - accuracy: 0.9583 - val_loss: 0.3028 - val_accuracy: 0.9510\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1632 - accuracy: 0.9624 - val_loss: 0.2976 - val_accuracy: 0.9496\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1576 - accuracy: 0.9640 - val_loss: 0.3384 - val_accuracy: 0.9517\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1535 - accuracy: 0.9649 - val_loss: 0.2919 - val_accuracy: 0.9537\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1429 - accuracy: 0.9674 - val_loss: 0.3487 - val_accuracy: 0.9538\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1314 - accuracy: 0.9692 - val_loss: 0.3305 - val_accuracy: 0.9542\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1365 - accuracy: 0.9704 - val_loss: 0.3314 - val_accuracy: 0.9530\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1275 - accuracy: 0.9719 - val_loss: 0.3681 - val_accuracy: 0.9487\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1181 - accuracy: 0.9721 - val_loss: 0.3530 - val_accuracy: 0.9543\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1194 - accuracy: 0.9727 - val_loss: 0.3697 - val_accuracy: 0.9559\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1100 - accuracy: 0.9745 - val_loss: 0.3487 - val_accuracy: 0.9557\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1053 - accuracy: 0.9759 - val_loss: 0.3786 - val_accuracy: 0.9573\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1084 - accuracy: 0.9757 - val_loss: 0.3519 - val_accuracy: 0.9536\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0997 - accuracy: 0.9769 - val_loss: 0.3849 - val_accuracy: 0.9558\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0989 - accuracy: 0.9780 - val_loss: 0.4082 - val_accuracy: 0.9560\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0882 - accuracy: 0.9780 - val_loss: 0.4297 - val_accuracy: 0.9537\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0874 - accuracy: 0.9800 - val_loss: 0.3994 - val_accuracy: 0.9565\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0900 - accuracy: 0.9789 - val_loss: 0.4110 - val_accuracy: 0.9567\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9804 - val_loss: 0.4054 - val_accuracy: 0.9548\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0791 - accuracy: 0.9808 - val_loss: 0.4046 - val_accuracy: 0.9563\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0825 - accuracy: 0.9812 - val_loss: 0.4335 - val_accuracy: 0.9564\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0785 - accuracy: 0.9819 - val_loss: 0.4745 - val_accuracy: 0.9563\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0777 - accuracy: 0.9824 - val_loss: 0.4750 - val_accuracy: 0.9560\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0773 - accuracy: 0.9826 - val_loss: 0.4630 - val_accuracy: 0.9571\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0723 - accuracy: 0.9837 - val_loss: 0.4595 - val_accuracy: 0.9542\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0714 - accuracy: 0.9839 - val_loss: 0.4551 - val_accuracy: 0.9581\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0691 - accuracy: 0.9834 - val_loss: 0.4828 - val_accuracy: 0.9578\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0658 - accuracy: 0.9841 - val_loss: 0.4918 - val_accuracy: 0.9562\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0648 - accuracy: 0.9848 - val_loss: 0.5575 - val_accuracy: 0.9538\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0650 - accuracy: 0.9846 - val_loss: 0.5332 - val_accuracy: 0.9568\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0629 - accuracy: 0.9854 - val_loss: 0.4897 - val_accuracy: 0.9577\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0623 - accuracy: 0.9861 - val_loss: 0.4806 - val_accuracy: 0.9578\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0584 - accuracy: 0.9864 - val_loss: 0.5057 - val_accuracy: 0.9602\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0569 - accuracy: 0.9868 - val_loss: 0.5133 - val_accuracy: 0.9595\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0571 - accuracy: 0.9865 - val_loss: 0.5246 - val_accuracy: 0.9584\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0610 - accuracy: 0.9862 - val_loss: 0.5623 - val_accuracy: 0.9567\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0549 - accuracy: 0.9874 - val_loss: 0.5658 - val_accuracy: 0.9567\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0585 - accuracy: 0.9871 - val_loss: 0.5505 - val_accuracy: 0.9570\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0606 - accuracy: 0.9867 - val_loss: 0.5583 - val_accuracy: 0.9586\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0545 - accuracy: 0.9875 - val_loss: 0.5730 - val_accuracy: 0.9598\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0510 - accuracy: 0.9879 - val_loss: 0.6298 - val_accuracy: 0.9575\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0479 - accuracy: 0.9883 - val_loss: 0.5668 - val_accuracy: 0.9582\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0518 - accuracy: 0.9881 - val_loss: 0.6253 - val_accuracy: 0.9597\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0539 - accuracy: 0.9880 - val_loss: 0.5943 - val_accuracy: 0.9603\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0481 - accuracy: 0.9885 - val_loss: 0.5833 - val_accuracy: 0.9614\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0479 - accuracy: 0.9885 - val_loss: 0.5647 - val_accuracy: 0.9607\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0479 - accuracy: 0.9888 - val_loss: 0.5914 - val_accuracy: 0.9617\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0429 - accuracy: 0.9892 - val_loss: 0.5976 - val_accuracy: 0.9596\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0454 - accuracy: 0.9892 - val_loss: 0.5861 - val_accuracy: 0.9622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0458 - accuracy: 0.9887 - val_loss: 0.6632 - val_accuracy: 0.9597\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0450 - accuracy: 0.9902 - val_loss: 0.6319 - val_accuracy: 0.9595\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0429 - accuracy: 0.9895 - val_loss: 0.6511 - val_accuracy: 0.9597\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0432 - accuracy: 0.9898 - val_loss: 0.6281 - val_accuracy: 0.9612\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0430 - accuracy: 0.9902 - val_loss: 0.6870 - val_accuracy: 0.9583\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0413 - accuracy: 0.9897 - val_loss: 0.6669 - val_accuracy: 0.9588\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0401 - accuracy: 0.9899 - val_loss: 0.6632 - val_accuracy: 0.9607\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0432 - accuracy: 0.9908 - val_loss: 0.6929 - val_accuracy: 0.9577\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0419 - accuracy: 0.9906 - val_loss: 0.6673 - val_accuracy: 0.9602\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0424 - accuracy: 0.9906 - val_loss: 0.6900 - val_accuracy: 0.9594\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0409 - accuracy: 0.9908 - val_loss: 0.7137 - val_accuracy: 0.9584\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0415 - accuracy: 0.9903 - val_loss: 0.7139 - val_accuracy: 0.9588\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0373 - accuracy: 0.9912 - val_loss: 0.7086 - val_accuracy: 0.9601\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0375 - accuracy: 0.9908 - val_loss: 0.7324 - val_accuracy: 0.9612\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0380 - accuracy: 0.9909 - val_loss: 0.7256 - val_accuracy: 0.9618\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0323 - accuracy: 0.9919 - val_loss: 0.7163 - val_accuracy: 0.9611\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0408 - accuracy: 0.9910 - val_loss: 0.7389 - val_accuracy: 0.9626\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0345 - accuracy: 0.9914 - val_loss: 0.7504 - val_accuracy: 0.9612\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.9912 - val_loss: 0.7676 - val_accuracy: 0.9599\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0371 - accuracy: 0.9916 - val_loss: 0.7955 - val_accuracy: 0.9597\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0370 - accuracy: 0.9914 - val_loss: 0.7599 - val_accuracy: 0.9600\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9922 - val_loss: 0.8028 - val_accuracy: 0.9605\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0365 - accuracy: 0.9916 - val_loss: 0.7878 - val_accuracy: 0.9593\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0337 - accuracy: 0.9922 - val_loss: 0.7935 - val_accuracy: 0.9613\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0344 - accuracy: 0.9918 - val_loss: 0.8098 - val_accuracy: 0.9615\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0333 - accuracy: 0.9923 - val_loss: 0.8469 - val_accuracy: 0.9579\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9922 - val_loss: 0.8547 - val_accuracy: 0.9592\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9923 - val_loss: 0.8144 - val_accuracy: 0.9592\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0290 - accuracy: 0.9927 - val_loss: 0.7980 - val_accuracy: 0.9616\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0304 - accuracy: 0.9926 - val_loss: 0.7967 - val_accuracy: 0.9596\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0295 - accuracy: 0.9925 - val_loss: 0.8120 - val_accuracy: 0.9613\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0303 - accuracy: 0.9927 - val_loss: 0.8317 - val_accuracy: 0.9599\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0323 - accuracy: 0.9926 - val_loss: 0.8252 - val_accuracy: 0.9617\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0327 - accuracy: 0.9921 - val_loss: 0.9089 - val_accuracy: 0.9588\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0297 - accuracy: 0.9931 - val_loss: 0.8596 - val_accuracy: 0.9586\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0302 - accuracy: 0.9928 - val_loss: 0.8936 - val_accuracy: 0.9600\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0264 - accuracy: 0.9935 - val_loss: 0.8762 - val_accuracy: 0.9580\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9928 - val_loss: 0.8717 - val_accuracy: 0.9596\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0324 - accuracy: 0.9926 - val_loss: 0.8954 - val_accuracy: 0.9592\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0336 - accuracy: 0.9925 - val_loss: 0.8472 - val_accuracy: 0.9603\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9926 - val_loss: 0.9200 - val_accuracy: 0.9591\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9926 - val_loss: 0.8829 - val_accuracy: 0.9619\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9932 - val_loss: 0.8519 - val_accuracy: 0.9618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x18a99ce4490>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터로 모델을 학습하기\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=128, validation_split=0.2) \n",
    "# validation_split 검증용 성능 평가를 통해 오버피팅을 확인할 수 있다/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "206b92d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 4.9813 - accuracy: 0.8491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.9813232421875, 0.8490999937057495]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf2b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "844b6cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 1s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n",
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c705e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num = 10\n",
    "print(y_train[num])\n",
    "plt.imshow(x_train[num], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd930d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000, 10)\n",
      "(10000, 28, 28, 1) (10000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "# 텐서플로우의 원핫인코딩 함수\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e4b66e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 3)         78        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 12, 12, 3)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 6)           456       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 4, 4, 6)           0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 96)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 84)                8148      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9532 (37.23 KB)\n",
      "Trainable params: 9532 (37.23 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "X = tf.keras.Input(shape=[28, 28, 1])\n",
    "H = tf.keras.layers.Conv2D(3, 5, activation=\"swish\")(X)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "H = tf.keras.layers.Conv2D(6, 5, activation=\"swish\")(H)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "H = tf.keras.layers.Flatten()(H)\n",
    "H = tf.keras.layers.Dense(84, activation=\"swish\")(H)\n",
    "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
    "model = tf.keras.Model(X, Y)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
    "model.summary(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e796ad1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "422/422 [==============================] - 7s 17ms/step - loss: 0.2919 - accuracy: 0.8919 - val_loss: 0.3678 - val_accuracy: 0.8682\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.2878 - accuracy: 0.8914 - val_loss: 0.4118 - val_accuracy: 0.8475\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.2858 - accuracy: 0.8930 - val_loss: 0.3845 - val_accuracy: 0.8635\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.2839 - accuracy: 0.8930 - val_loss: 0.3719 - val_accuracy: 0.8705\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.2809 - accuracy: 0.8947 - val_loss: 0.3915 - val_accuracy: 0.8600\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.2785 - accuracy: 0.8946 - val_loss: 0.4088 - val_accuracy: 0.8595\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 9s 20ms/step - loss: 0.2755 - accuracy: 0.8969 - val_loss: 0.3740 - val_accuracy: 0.8687\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.2742 - accuracy: 0.8961 - val_loss: 0.3691 - val_accuracy: 0.8720\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.2728 - accuracy: 0.8975 - val_loss: 0.3885 - val_accuracy: 0.8662\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.2696 - accuracy: 0.8981 - val_loss: 0.3692 - val_accuracy: 0.8697\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 9s 20ms/step - loss: 0.2695 - accuracy: 0.8977 - val_loss: 0.3827 - val_accuracy: 0.8708\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 9s 20ms/step - loss: 0.2687 - accuracy: 0.8985 - val_loss: 0.4309 - val_accuracy: 0.8485\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.2670 - accuracy: 0.8994 - val_loss: 0.3813 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.2650 - accuracy: 0.8991 - val_loss: 0.4094 - val_accuracy: 0.8627\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.2644 - accuracy: 0.8999 - val_loss: 0.4026 - val_accuracy: 0.8662\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.2618 - accuracy: 0.9003 - val_loss: 0.3986 - val_accuracy: 0.8662\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.2625 - accuracy: 0.9015 - val_loss: 0.4048 - val_accuracy: 0.8668\n",
      "Epoch 18/100\n",
      " 49/422 [==>...........................] - ETA: 7s - loss: 0.2537 - accuracy: 0.9016"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function(\u001b[38;5;241m*\u001b[39margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36f81080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4333 - accuracy: 0.8646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4332684576511383, 0.8646000027656555]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee5b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e22ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c548cd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
