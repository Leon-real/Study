# 효율적인 성능 평가 방법

지금까지 모델을 선언하고 학습한 후 바로 평가를 진행하였다.  
일반화 성능, 즉 이후 새로운 데이터에 대한 모델의 성능을 예측하지 못한 상태에서 최종 평가를 수행한다.  따라서 더욱 정교한 평가 절차가 필요하다.  

### K-분할 교차 검증 개념

- K-Fold Cross Validation
- 모든 데이터가 평가에 한번, 학습에 k-1번 사용
- k개의 분할(Fold)에 대한 성능을 예측 → 평균과 표준편차 계산 → 일반화 성능
- 단, k는 2 이상이 되어야 한다.(최소한 한 개씩의 학습용, 검증용 데이터가 필요하다)
- 장점
    - 모든 데이터를 학습과 평가에 사용할 수 있음
    - 반복 학습과 평가를 통해 정확도를 향상시킬 수 있음
    - 데이터가 부족해서 발생하는 과소적합 문제를 방지할 수 있음
    - 평가에 사용되는 데이터의 편향을 막을 수 있음
    - 좀 더 일반화된 모델을 만들 수 있음
- 단점
    - 반복 횟수가 많아서 모델 학습과 평가에 많은 시간이 소요됨
- **주의** : 데이터는 학습용 평가용으로 분리하고, 평가용 데이터는 이후 최종 평가에 사용할 데이터이기 때문에 성능 검증에 사용하면 안된다. **즉, K-분할은 x_train, y_train 데이터만을 대상으로 한다.**

### K-분할 교차 검증 사용 방법

- 모델 선언 후 cross_val_score(모델, x_train, y_train, 분할 개수) 형태로 사용
- 기본 분할 개수(cv) 값은 5이며, 필요에 따라 적절히 조절할 수 있음
- cross_val_score 함수 결과로 얻은 성능들의 평균을 모델의 성능으로 봄
- 물론 실제 평가에서 얻은 성능이 이 성능보다 더 높거나 낮을 수 있음

```python
# 1단계: 불러오기
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
# 2단계: 선언하기
model = DecisionTreeClassifier(max_depth=3)
# 3단계: 검증하기
cv_score = cross_val_score(model, x_train, y_train, cv=10)
# 확인
print(cv_score)
print(cv_score.mean())
```